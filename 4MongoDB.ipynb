{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8b95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "#import numpy\n",
    "#import datetime\n",
    "import certifi\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.types import String, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d7f6f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SQL Alchemy Version: 2.0.43\n",
      "Running PyMongo Version: 4.15.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running SQL Alchemy Version: {sqlalchemy.__version__}\")\n",
    "print(f\"Running PyMongo Version: {pymongo.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c629e4",
   "metadata": {},
   "source": [
    "### Declare & Assign Connection Variables for the MongoDB Server, the MySQL Server & Databases with which You'll be Working "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28890801",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_args = {\n",
    "    \"uid\" : \"root\",\n",
    "    \"pwd\" : \"SoupbruhSm3lls!\",\n",
    "    \"hostname\" : \"localhost\",\n",
    "    \"dbname\" : \"sakila_dw\"\n",
    "}\n",
    "\n",
    "# The 'cluster_location' must either be \"atlas\" or \"local\".\n",
    "mongodb_args = {\n",
    "    \"user_name\" : \"ethan\", #hkj7zy\n",
    "    \"password\" : \"ethan\", #SoupBruhSm3lls\n",
    "    \"cluster_name\" : \"Cluster0\",\n",
    "    \"cluster_subnet\" : \"gjazvwc\",\n",
    "    \"cluster_location\" : \"atlas\", # \"local\"\n",
    "    \"db_name\" : \"sakila_nosql\"\n",
    "}\n",
    "# Global vars\n",
    "MONGO_COLLECTION = \"customer_profiles\" \n",
    "STAGING_TABLE = \"stg_customer_profiles\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928a06",
   "metadata": {},
   "source": [
    "### Define Functions for Getting Data From and Setting Data Into Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eabb5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(sql_query, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    dframe = pd.read_sql(text(sql_query), connection);\n",
    "    connection.close()\n",
    "    \n",
    "    return dframe\n",
    "    \n",
    "\n",
    "def set_dataframe(df, table_name, pk_column, db_operation, **args):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    conn_str = f\"mysql+pymysql://{args['uid']}:{args['pwd']}@{args['hostname']}/{args['dbname']}\"\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        connection.execute(text(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\"))\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "\n",
    "def get_mongo_client(**args):\n",
    "    '''Validate proper input'''\n",
    "    if args[\"cluster_location\"] not in ['atlas', 'local']:\n",
    "        raise Exception(\"You must specify either 'atlas' or 'local' for the cluster_location parameter.\")\n",
    "    \n",
    "    else:\n",
    "        if args[\"cluster_location\"] == \"atlas\":\n",
    "            connect_str = f\"mongodb+srv://{args['user_name']}:{args['password']}@\"\n",
    "            connect_str += f\"{args['cluster_name']}.{args['cluster_subnet']}.mongodb.net\"\n",
    "            client = pymongo.MongoClient(connect_str, tlsCAFile=certifi.where())\n",
    "            \n",
    "        elif args[\"cluster_location\"] == \"local\":\n",
    "            client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "        \n",
    "    return client\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(mongo_client, db_name, collection, query):\n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = mongo_client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    mongo_client.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_mongo_collections(mongo_client, db_name, data_directory, json_files):\n",
    "    db = mongo_client[db_name]\n",
    "    \n",
    "    for file in json_files:\n",
    "        db.drop_collection(file)\n",
    "        json_file = os.path.join(data_directory, json_files[file])\n",
    "        with open(json_file, 'r') as openfile:\n",
    "            json_object = json.load(openfile)\n",
    "            file = db[file]\n",
    "            result = file.insert_many(json_object)\n",
    "        \n",
    "    mongo_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a3a43",
   "metadata": {},
   "source": [
    "### Build MySQL engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9772c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mysql_engine():\n",
    "    conn_str = f\"mysql+pymysql://{mysql_args['uid']}:{mysql_args['pwd']}@\" \\\n",
    "               f\"{mysql_args['hostname']}/{mysql_args['dbname']}\"\n",
    "    return create_engine(conn_str, pool_recycle=3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747a78",
   "metadata": {},
   "source": [
    "### Extract Data from MongoDB Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d79acc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mongo_client = get_mongo_client(**mongodb_args)\n",
    "df = get_mongo_dataframe(\n",
    "    mongo_client,\n",
    "    db_name=mongodb_args[\"db_name\"],\n",
    "    collection=MONGO_COLLECTION,\n",
    "    query={}  # pull all docs; your helper already drops _id\n",
    ")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"Mongo collection is empty; nothing to merge.\")\n",
    "    raise SystemExit(0)\n",
    "\n",
    "# Get rid of other columns we don't need (There are not any other columns but hypothetically if there were this would account for it)\n",
    "keep_cols = [\"email\", \"loyalty_tier\", \"loyalty_score\"]\n",
    "for col in keep_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# normalize data\n",
    "df[\"email\"] = df[\"email\"].astype(str).str.strip().str.lower()\n",
    "df[\"loyalty_tier\"] = df[\"loyalty_tier\"].astype(str).str.strip().str.upper()\n",
    "df[\"loyalty_score\"] = pd.to_numeric(df[\"loyalty_score\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "df = df.dropna(subset=[\"email\"])\n",
    "df = df.drop_duplicates(subset=[\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829c2715",
   "metadata": {},
   "source": [
    "### Load to MySQL by building staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2f7c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = mysql_engine()\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {STAGING_TABLE} (\n",
    "            email VARCHAR(255) NOT NULL,\n",
    "            loyalty_tier VARCHAR(32),\n",
    "            loyalty_score INT,\n",
    "            PRIMARY KEY (email)\n",
    "        )\n",
    "    \"\"\"))\n",
    "\n",
    "set_dataframe(\n",
    "    df,\n",
    "    table_name=STAGING_TABLE,\n",
    "    pk_column=\"email\",\n",
    "    db_operation=\"update\",\n",
    "    **mysql_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47178c4",
   "metadata": {},
   "source": [
    "### Merge into dim_customer table on MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65e7a695",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    # Again check first if columns exist\n",
    "    exists_tier = conn.execute(text(\"\"\"\n",
    "        SELECT 1\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_SCHEMA = :db AND TABLE_NAME = 'dim_customer' AND COLUMN_NAME = 'loyalty_tier'\n",
    "        LIMIT 1\n",
    "    \"\"\"), {\"db\": mysql_args[\"dbname\"]}).scalar()\n",
    "\n",
    "    if not exists_tier:\n",
    "        conn.execute(text(\"ALTER TABLE dim_customer ADD COLUMN loyalty_tier VARCHAR(32)\"))\n",
    "\n",
    "    exists_score = conn.execute(text(\"\"\"\n",
    "        SELECT 1\n",
    "        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "        WHERE TABLE_SCHEMA = :db AND TABLE_NAME = 'dim_customer' AND COLUMN_NAME = 'loyalty_score'\n",
    "        LIMIT 1\n",
    "    \"\"\"), {\"db\": mysql_args[\"dbname\"]}).scalar()\n",
    "\n",
    "    if not exists_score:\n",
    "        conn.execute(text(\"ALTER TABLE dim_customer ADD COLUMN loyalty_score INT\"))\n",
    "\n",
    "    # Normalize warehouse emails once to ensure join success\n",
    "    conn.execute(text(\"UPDATE dim_customer SET email = LOWER(TRIM(email))\"))\n",
    "\n",
    "    # Merge\n",
    "    conn.execute(text(f\"\"\"\n",
    "        UPDATE dim_customer d\n",
    "        JOIN {STAGING_TABLE} s ON s.email = d.email\n",
    "        SET d.loyalty_tier  = s.loyalty_tier,\n",
    "            d.loyalty_score = s.loyalty_score\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10272202",
   "metadata": {},
   "source": [
    "### How many customers now have a loyalty tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bb8e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mongo enrichment complete. Customers updated: 20\n"
     ]
    }
   ],
   "source": [
    "# Check if adding enrichment to customers table was successful\n",
    "with engine.connect() as conn:\n",
    "    enriched = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) FROM dim_customer\n",
    "        WHERE loyalty_tier IS NOT NULL OR loyalty_score IS NOT NULL\n",
    "    \"\"\")).scalar()\n",
    "    print(f\"Mongo enrichment complete. Customers updated: {enriched}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
